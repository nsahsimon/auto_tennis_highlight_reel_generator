{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def select_video_file():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4;*.mov;*.avi;*.mkv\")])\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = select_video_file()\n",
    "print(f\"selected video path: {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['picasso', 'was', 'the', 'number', '1', 'artist', 'during', 'the', '2nd', 'world', 'war']\n"
     ]
    }
   ],
   "source": [
    "text = \"picasso was the number 1 artist during the 2nd world war\"\n",
    "\n",
    "texts = str.split(text)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'picassowasthenumber1artistduringthe2ndworldwar'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(texts)\n",
    "print(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1274: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a7072d00b65c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msampleImagePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"images/sample_5.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampleImagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0measyocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1274: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "sampleImagePath = \"images/sample_5.png\"\n",
    "image  = cv2.imread(sampleImagePath)\n",
    "cv2.waitKey()\n",
    "reader = easyocr.Reader(['en'])\n",
    "results = reader.readtext(image)\n",
    "for result in results:\n",
    "    print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\SIMON\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From C:\\Users\\SIMON\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Looking for C:\\Users\\SIMON\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the Keras-OCR model\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 380, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the image\n",
    "# image = cv2.imread('images/sample_5.png')\n",
    "image = keras_ocr.tools.read('images/sample_2.png')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[('roid', array([[ 82.,  48.],\n",
      "       [151.,  48.],\n",
      "       [151.,  78.],\n",
      "       [ 82.,  78.]], dtype=float32)), ('27', array([[220.,  49.],\n",
      "       [285.,  49.],\n",
      "       [285.,  78.],\n",
      "       [220.,  78.]], dtype=float32)), ('oang', array([[ 57., 105.],\n",
      "       [157., 105.],\n",
      "       [157., 136.],\n",
      "       [ 57., 136.]], dtype=float32)), ('n', array([[221., 116.],\n",
      "       [241., 116.],\n",
      "       [241., 132.],\n",
      "       [221., 132.]], dtype=float32))]]\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray\", gray)\n",
    "cv2.waitKey(1)\n",
    "thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "cv2.imshow(\"thresh\", thresh_image)\n",
    "cv2.waitKey(1)\n",
    "canny_image = cv2.Canny(gray, 115, 150)\n",
    "cv2.imshow(\"canny_image\", canny_image)\n",
    "cv2.waitKey(1)\n",
    "final = cv2.merge([canny_image, canny_image, canny_image])\n",
    "predictions = pipeline.recognize([final],)\n",
    "print()\n",
    "print(predictions)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6e22e47002f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "keras_ocr.tools.cv2.imshow(image)\n",
    "keras_ocr.tools.cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\SIMON\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\SIMON\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b01af270c7cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# image = cv2.imread('images/sample_5.png')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/sample_2.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Perform thresholding to create a binary image\n",
    "# thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# # Perform dilation to improve text detection\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "# dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "# Use Keras-OCR to detect the text\n",
    "predictions = pipeline.recognize([image])\n",
    "\n",
    "# Print the detected text\n",
    "for prediction in predictions[0]:\n",
    "    print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained East text detector\n",
    "net = cv2.dnn.readNet('models/frozen_east_text_detection.pb')\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/5.png')\n",
    "\n",
    "# Get the height and width of the image\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# Set the new height and width for the resized image\n",
    "(newW, newH) = (320, 320)\n",
    "\n",
    "# Calculate the scale factors for the resized image\n",
    "rW = w / float(newW)\n",
    "rH = h / float(newH)\n",
    "\n",
    "# Resize the image to the new dimensions\n",
    "resized = cv2.resize(image, (newW, newH))\n",
    "\n",
    "# Create a 4D blob from the resized image\n",
    "blob = cv2.dnn.blobFromImage(resized, 1.0, (newW, newH), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "\n",
    "# Set the input blob for the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Get the output layers of the network\n",
    "(outputLayers, _) = net.getUnconnectedOutLayers()\n",
    "\n",
    "# Forward pass through the network\n",
    "scores, geometry = net.forward(outputLayers)\n",
    "\n",
    "# Get the number of rows and columns in the scores\n",
    "(numRows, numCols) = scores.shape[2:4]\n",
    "\n",
    "# Initialize lists for the bounding boxes and confidence scores\n",
    "boxes = []\n",
    "confidences = []\n",
    "\n",
    "# Loop over the rows of the scores\n",
    "for y in range(0, numRows):\n",
    "    # Extract the scores and geometry for the current row\n",
    "    scoresData = scores[0, 0, y]\n",
    "    xData0 = geometry[0, 0, y]\n",
    "    xData1 = geometry[0, 1, y]\n",
    "    xData2 = geometry[0, 2, y]\n",
    "    xData3 = geometry[0, 3, y]\n",
    "    anglesData = geometry[0, 4, y]\n",
    "\n",
    "    # Loop over the columns of the scores\n",
    "    for x in range(0, numCols):\n",
    "        # If the score for the current pixel is below the threshold, skip it\n",
    "        if scoresData[x] < 0.5:\n",
    "            continue\n",
    "\n",
    "        # Calculate the offset for the current pixel\n",
    "        (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "        # Extract the angle and cosine of the angle for the current pixel\n",
    "        angle = anglesData[x]\n",
    "        cos = np.cos(angle)\n",
    "        sin = np.sin(angle)\n",
    "\n",
    "        # Calculate the width and height of the bounding box\n",
    "        h = xData0[x] + xData2[x]\n",
    "        w = xData1[x] + xData3[x]\n",
    "\n",
    "        # Calculate the corners of the bounding box\n",
    "        endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "        endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "        startX = int(endX - w)\n",
    "        startY = int(endY - h)\n",
    "\n",
    "        # Add the bounding box and confidence score to the lists\n",
    "        boxes.append((startX, startY, endX, endY))\n",
    "        confidences.append(scoresData[x])\n",
    "\n",
    "# Apply non-maximum suppression to remove overlapping boxes\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "# Loop over the remaining boxes and draw them on the original image\n",
    "for\n",
    "\n",
    "\n",
    "\n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    boxes_unscaled = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    if len(boxes_unscaled) > 0:\n",
    "        videoContainsText = True\n",
    "\n",
    "    boxes = []\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes_unscaled:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = startX / W\n",
    "        startY = startY / H\n",
    "        endX = endX / W\n",
    "        endY = endY / H\n",
    "        keyAreas.append((startX, startY, endX, endY))\n",
    "        boxes.append((startX, startY, endX, endY))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
